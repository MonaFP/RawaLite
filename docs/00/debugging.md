# RawaLite â€“ Debugging-Workflow (Safe Edition)  

Dieses Dokument beschreibt den empfohlenen **Ablauf zur Fehlersuche** in RawaLite. Durch einen strukturierten Workflow werden Probleme effizient, reproduzierbar und faktenbasiert gelÃ¶st. Jede Analyse soll den unten definierten Schritten folgen, um Zufallsfunde und Fehlversuche zu vermeiden.

WICHTIG â€“ NICHT VERHANDELBAR
In diesem Projekt gelten die RawaLite Coding Instructions als unverÃ¤nderliche Referenz-Dokumente.

Du darfst keine Ã„nderungen an PROJECT_OVERVIEW.md, RawaLite â€“ AI Coding Instructions oder anderen Projekt-Dokumenten vornehmen.

Du darfst die Instruktionen nicht kÃ¼rzen, umschreiben, interpretieren oder in anderes Format bringen.

Wenn du in Konflikt mit diesen Instruktionen kommst: nicht improvisieren, sondern sofort nachfragen.

Dein Fokus liegt ausschlieÃŸlich auf Code-Ã„nderungen, Bugfixes, Tests und Umsetzung innerhalb bestehender Patterns.

Die Dokumentation ist Read-Only und darf von dir niemals verÃ¤ndert oder Ã¼berschrieben werden.

BestÃ¤tige bitte jedes Mal, dass du die Dokumentation nicht angepasst hast.

## Systematischer ProblemlÃ¶sungsprozess (Safe Edition)

Dieser Ansatz ist **verbindlicher Standard** fÃ¼r alle Debugging- und ProblemlÃ¶sungsaufgaben in RawaLite.  
Er basiert auf den Lessons Learned vom 15. September 2025 und ist Teil der Safe Edition.

### Vier Prinzipien (Doâ€™s)
1. **Documentation-First**  
   Immer zuerst die relevante Dokumentation und Regeln lesen. Kein Einstieg ins Code-Hacking ohne Doku-Basis.
2. **Data-First**  
   Entscheidungen erst nach vollstÃ¤ndiger Datensammlung (Logs, Status, Configs). Keine LÃ¶sungen aus BauchgefÃ¼hl.
3. **Simple-First**  
   Zuerst die einfachste funktionierende LÃ¶sung umsetzen. KomplexitÃ¤t nur, wenn nÃ¶tig.
4. **Existing-First**  
   Bestehende Prozesse, Tools und Guards nutzen, bevor etwas Neues erfunden wird.

### Anti-Patterns (Donâ€™ts)
- âŒ Code-First Debugging (Code Ã¶ffnen ohne Doku/Analyse)  
- âŒ Solution-First Design (LÃ¶sung entwerfen ohne Datenlage)  
- âŒ Complex-First Implementation (Over-Engineering)  
- âŒ Invention-First Approach (Neuentwicklung trotz vorhandener Tools)

### Zero-Tolerance & DoD
Dieser Prozess gilt **fÃ¼r alle Probleme**, auch vermeintlich kleine.  
Kein Schritt darf Ã¼bersprungen oder als â€nicht kritischâ€œ abgetan werden.

**Definition of Done (DoD):**
- `pnpm typecheck` â†’ 0 Fehler  
- `pnpm lint --max-warnings=0` â†’ 0 Fehler/Warnungen  
- Alle Guards (`guard:external`, `guard:pdf`, `validate:ipc`, `validate:versions`, `guard:todos`, `validate:esm`) â†’ grÃ¼n  
- `pnpm test --run` â†’ alle Tests grÃ¼n und deterministisch  
- **Keine** VerstÃ¶ÃŸe (`require`, `module.exports`, `window.open`, `target="_blank"`, `shell.openExternal`, `http(s)://`, `TODO/FIXME/HACK`) in Code oder Templates



## ğŸ”„ Debugging-Workflow  
Der folgende Workflow stellt sicher, dass Probleme systematisch angegangen werden:  

** Zuerst: Ã¼berprÃ¼fen, ob es das Problem bereits gab und schonmal behoben wurde.**

1. **Problem definieren & reproduzieren:** Fehlerbild klar beschreiben und zuverlÃ¤ssig reproduzierbar machen (Testfall erstellen).  
2. **Informationen sammeln:** Relevante **Logs**, Einstellungen und Umgebungsdaten erfassen; Ist- und Soll-Verhalten vergleichen.  
3. **Hypothese aufstellen:** Auf Basis der Fakten eine plausible **Ursachenannahme** formulieren (worin kÃ¶nnte das Problem begrÃ¼ndet sein?).  
4. **Test planen:** Einen gezielten **Versuch** entwerfen, um die Hypothese zu Ã¼berprÃ¼fen â€“ **nur eine Variable Ã¤ndern** bzw. einen isolierten Fix/Workaround vorbereiten.  
5. **Test durchfÃ¼hren:** Den geplanten Versuch ausfÃ¼hren und das Systemverhalten beobachten. **Keine parallelen Ã„nderungen**, um den Effekt eindeutig zuzuordnen.  
6. **Ergebnis auswerten:** Resultat des Tests analysieren. Wurde die Hypothese **bestÃ¤tigt oder widerlegt**? Befunde festhalten (z.â€¯B. in Form von Logs, Screenshots).  
7. **Iterieren oder abschlieÃŸen:** Falls die Hypothese falsch war, aus den neuen Erkenntnissen eine nÃ¤chste Hypothese ableiten und Schritt 4â€“6 wiederholen. Trifft die Hypothese zu, zur Fehlerbehebung Ã¼bergehen.  
8. **LÃ¶sung verifizieren & dokumentieren:** Sobald die **Root Cause** feststeht, dauerhafte Korrektur implementieren. AnschlieÃŸend den Fix testen, um den Erfolg zu bestÃ¤tigen. Alle durchgefÃ¼hrten Versuche und Schlussfolgerungen im **Lessons Learned** Dokument zum Thema festhalten.

## ğŸ“‹ Checkliste (Debugging)  
* [ ] **Fehler reproduziert** â€“ Problem tritt verlÃ¤sslich in einer Testumgebung auf.  
* [ ] **Logs analysiert** â€“ Wichtige Log-EintrÃ¤ge, Fehlermeldungen und SystemzustÃ¤nde geprÃ¼ft.  
* [ ] **Hypothese gebildet** â€“ MÃ¶gliche Ursache basierend auf Fakten formuliert.  
* [ ] **Gezielter Test durchgefÃ¼hrt** â€“ Eine einzelne Ã„nderung/ MaÃŸnahme zur ÃœberprÃ¼fung umgesetzt.  
* [ ] **Ergebnis bewertet** â€“ Ausgang des Tests untersucht (Hypothese bestÃ¤tigt oder verworfen?).  
* [ ] **Versuch dokumentiert** â€“ DurchgefÃ¼hrte Tests und Befunde schriftlich festgehalten (Lessons Learned Eintrag).  
* [ ] **Ursache gefunden** â€“ Falls nein: neue Hypothese und nÃ¤chster Test geplant; falls ja: Fix implementiert und Erfolg geprÃ¼ft.
* [ ] **Ergebnisse dÃ¼rfen nicht geraten** werden â†’ immer Entwickler fragen.  
* [ ] Nur Fakten, keine Spekulationen.  
* [ ] Keine Redundanzen 